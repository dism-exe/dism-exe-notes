/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var Se=Object.defineProperty;var it=Object.getOwnPropertyDescriptor;var nt=Object.getOwnPropertyNames;var ot=Object.prototype.hasOwnProperty;var st=(l,e)=>{for(var t in e)Se(l,t,{get:e[t],enumerable:!0})},at=(l,e,t,r)=>{if(e&&typeof e=="object"||typeof e=="function")for(let i of nt(e))!ot.call(l,i)&&i!==t&&Se(l,i,{get:()=>e[i],enumerable:!(r=it(e,i))||r.enumerable});return l};var lt=l=>at(Se({},"__esModule",{value:!0}),l);var pt={};st(pt,{default:()=>fe});module.exports=lt(pt);var rt=require("obsidian");var ve=require("obsidian");var q=require("obsidian"),X=class extends q.Modal{constructor(e,t,r){super(e),this.folderName=t,this.folderPath=r,this.result=!1,this.modalPromise=new Promise(i=>{this.resolveModalPromise=i})}onOpen(){let{contentEl:e}=this;e.createEl("h2",{text:`[ChatGPT MD] No ${this.folderName} folder found.`}),e.createEl("p",{text:`If you choose "Yes, Create", the plugin will automatically create a folder at: ${this.folderPath}. You can change this path in the plugin settings.`}),new q.Setting(e).addButton(t=>t.setButtonText("Yes, Create Folder").setTooltip("Create folder").setCta().onClick(()=>{this.result=!0,this.resolveModalPromise(this.result),this.close()})),new q.Setting(e).addButton(t=>t.setButtonText("No, I'll create it myself").setTooltip("Cancel").setCta().onClick(()=>{this.result=!1,this.resolveModalPromise(this.result),this.close()}))}waitForModalValue(){return this.modalPromise}onClose(){let{contentEl:e}=this;e.empty()}};var ye=async(l,e,t)=>{let r=new X(l,e,t);r.open();let i=await r.waitForModalValue();return i?(console.log("[ChatGPT MD] Creating folder"),await l.vault.createFolder(t)):console.log("[ChatGPT MD] Not creating folder"),i};var G=class{constructor(e){this.app=e}async writeInferredTitle(e,t){var s,a;let r=e.file;if(!r)throw new Error("No file is currently open");let i=this.sanitizeFileName(t),n=(a=(s=r.parent)==null?void 0:s.path)!=null?a:"/",o=`${n}/${i}.md`;for(let c=1;await this.app.vault.adapter.exists(o);c++)o=`${n}/${i} (${c}).md`;try{await this.app.fileManager.renameFile(r,o)}catch(c){throw new ve.Notice("[ChatGPT MD] Error writing inferred title to editor"),console.log("[ChatGPT MD] Error writing inferred title to editor",c),c}}sanitizeFileName(e){return e.replace(/[\\/:*?"<>|]/g,"-")}async ensureFolderExists(e,t){return!await this.app.vault.adapter.exists(e)&&!await ye(this.app,t,e)?(new ve.Notice(`[ChatGPT MD] No ${t} found. One must be created to use the plugin. Set one in settings and make sure it exists.`),!1):!0}async createNewFile(e,t){return this.app.vault.create(e,t)}async readFile(e){return this.app.vault.read(e)}async getLinkedNoteContent(e){try{let t=this.app.metadataCache.getFirstLinkpathDest(e,"");return t?await this.app.vault.read(t):null}catch(t){return console.error(`Error reading linked note: ${e}`,t),null}}formatDate(e,t){return e.toISOString().replace(/[-:]/g,"").replace(/\..+/,"")}};var g="ollama",h="openai",d="openrouter",S="lmstudio",Re={[h]:"/v1/chat/completions",[d]:"/api/v1/chat/completions",[g]:"/api/chat",[S]:"/v1/chat/completions"},Me="add-comment-block",we="add-hr",Pe="call-chatgpt-api",Ie="stop-streaming",be="move-to-chat",Oe="infer-title",Ne="choose-chat-template",De="clear-chat",Le=`I am sorry. There was an authorization issue with the external API (Status 401).
Please check your API key in the settings`,Fe=`I am sorry. There was an issue reaching the network.
Please check your network connection.`,xe="I am sorry, your request looks wrong. Please check your URL or model name in the settings or frontmatter.",Z="I am sorry, I could not answer your request because of an error, here is what went wrong:",Ae="chatFolder",$e="chatTemplateFolder",u=`

`,O=/---[\s\S]*?---/g,ke=/\[\[([^\][]+)\]\]/g,Ue=/\[([^\]]+)\]\(([^()]+)\)/g,Ge=`=begin-chatgpt-md-comment${u}`,He="=end-chatgpt-md-comment",Ve=3,Ee=6,Ke="English",Be=4,Q="YYYYMMDDhhmmss",We="Failed to fetch",Ce="__chatgpt_plugin",H=`<hr class="${Ce}">`,b="role::",N="assistant",ee="developer",qe="system",T="user",te=`---
system_commands: ['I am a helpful assistant.']
frequency_penalty: 0
max_tokens: 300
model: gpt-4.1-mini
presence_penalty: 0
stream: true
temperature: 1
---`,Y=6e3,re=`You are an AI assistant integrated into Obsidian through the ChatGPT MD plugin. You are helping a user who is working within their Obsidian vault - a personal knowledge management system where they store notes, thoughts, and information in Markdown format.

Key context:
- The user is writing in Markdown format within Obsidian
- They may reference other notes in their vault using [[wiki links]] or standard [markdown links](url)
- Your responses will be inserted directly into their Markdown document
- Be concise but helpful, and format your responses appropriately for Markdown
- If you provide code examples, use proper markdown code blocks with language specification
- When suggesting organizational strategies, consider that this is within a personal knowledge management context
- The user may be taking notes, brainstorming, writing, researching, or organizing information

Code block formatting requirements:
- Code blocks must start and end with exactly 3 backticks (\`\`\`) on a new line
- There should be no whitespace before the opening or closing backticks
- The language name should be specified immediately after the opening backticks
- The actual code should start on a new line after the language specification
- Example format:
\`\`\`javascript
console.log("Hello World");
\`\`\`

Inline code formatting requirements:
- Use single backticks (\`) for inline code references like filenames (e.g., \`example.md\`), variable names (e.g., \`myVariable\`), or short code snippets referenced within a paragraph.
- Always ensure that single backticks are properly closed to avoid breaking Markdown rendering. For example, use \`code\` not \`code.

Table formatting requirements:
- Use standard Markdown table syntax.
- Tables should NOT be wrapped in code blocks.

Respond naturally and helpfully while being mindful of this Obsidian/note-taking context.`;var Ye=l=>{let t=(l.match(/```/g)||[]).length%2!==0;return t&&console.log("[ChatGPT MD] Unclosed code block detected"),t};var ct=l=>{let e=l.replace(/[-/\\^$*+?.()|[\]{}]/g,"\\$&").replace("YYYY","\\d{4}").replace("MM","\\d{2}").replace("DD","\\d{2}").replace("hh","\\d{2}").replace("mm","\\d{2}").replace("ss","\\d{2}");return new RegExp(`^${e}$`)},je=(l="",e)=>(l==null?void 0:l.length)==e.length&&ct(e).test(l),D=l=>l===0?"":l>Ee?"#".repeat(Ee)+" ":"#".repeat(l)+" ",j=(l,e,t)=>`${u}${H}${u}${l}${b}${e}${t?`<span style="font-size: small;"> (${t})</span>`:""}${u}`,ie=l=>{let t=l.replace(/^---\n/,"").replace(/\n---$/,"").split(`
`),r={},i=null,n=[];for(let o=0;o<t.length;o++){let s=t[o].trim();if(!s)continue;if(i!==null)if(s.startsWith("-")){let m=s.substring(1).trim();(m.startsWith("'")&&m.endsWith("'")||m.startsWith('"')&&m.endsWith('"'))&&(m=m.substring(1,m.length-1)),n.push(m);continue}else r[i]=n,i=null,n=[];let a=s.indexOf(":");if(a===-1)continue;let c=s.substring(0,a).trim(),p=s.substring(a+1).trim();if(p===""&&o+1<t.length&&t[o+1].trim().startsWith("-")){i=c,n=[];continue}p.startsWith("[")&&p.endsWith("]")?r[c]=p.slice(1,-1).split(",").map(m=>{let f=m.trim();return f.startsWith("'")&&f.endsWith("'")||f.startsWith('"')&&f.endsWith('"')?f.slice(1,-1):f}):p==="true"?r[c]=!0:p==="false"?r[c]=!1:p==="null"?r[c]=null:isNaN(Number(p))?r[c]=p:r[c]=Number(p)}return i!==null&&(r[i]=n),r};var V=class{addHorizontalRule(e,t,r){let i=`${u}<hr class="${Ce}">${u}${D(r)}${b}${t}${u}`,n=e.getCursor();e.replaceRange(i,n),e.setCursor(n.line+i.split(`
`).length-1,0)}appendMessage(e,t,r){let i=D(r),n=j(i,N),o=j(i,T);e.replaceRange(`${n}${t}${o}`,e.getCursor())}clearChat(e){let r=e.getValue().match(O);if(r!=null&&r.length){let[i]=r;e.setValue(i),e.setCursor({line:e.lastLine()+1,ch:0})}else e.setValue("")}moveCursorToEnd(e){try{let r={line:e.lastLine()+1,ch:0};e.setCursor(r)}catch(t){throw new Error("Error moving cursor to end of file"+t)}}addCommentBlock(e,t,r){let i=e.getCursor(),n=`${t}${u}${r}`;e.replaceRange(n,i),e.setCursor({line:i.line+1,ch:i.ch})}};var K=class{constructor(e,t){this.fileService=e;this.notificationService=t}findLinksInMessage(e){let t=[{regex:ke,fullMatchIndex:0,titleIndex:1},{regex:Ue,fullMatchIndex:0,titleIndex:2}],r=[],i=new Set;for(let{regex:n,fullMatchIndex:o,titleIndex:s}of t)for(let a of e.matchAll(n)){let c=a[o],p=a[s];p&&!i.has(p)&&!p.startsWith("http://")&&!p.startsWith("https://")&&(r.push({link:c,title:p}),i.add(p))}return r}splitMessages(e){return e?e.split(H):[]}removeYAMLFrontMatter(e){return e&&e.replace(O,"").trim()}removeCommentsFromMessages(e){try{let t=/=begin-chatgpt-md-comment[\s\S]*?=end-chatgpt-md-comment/g;return e.replace(t,"")}catch(t){return this.notificationService.showError("Error removing comments from messages: "+t),e}}extractRoleAndMessage(e){try{if(!e.includes(b))return{role:T,content:e};let[t,...r]=e.split(b)[1].split(`
`);return{role:this.cleanupRole(t),content:r.join(`
`).trim()}}catch(t){return this.notificationService.showError("Failed to extract role and message: "+t),{role:T,content:e}}}cleanupRole(e){let t=e.trim().toLowerCase(),i=[T,N].find(n=>t.includes(n));return i||(this.notificationService.showWarning(`Unknown role: "${e}", defaulting to user`),T)}cleanMessagesFromNote(e){return this.splitMessages(this.removeYAMLFrontMatter(e.getValue())).map(r=>this.removeCommentsFromMessages(r))}async getMessagesFromEditor(e,t){let r=this.cleanMessagesFromNote(e);r=await Promise.all(r.map(async n=>{let o=this.findLinksInMessage(n);for(let s of o)try{let a=await this.fileService.getLinkedNoteContent(s.title);if(a){let c=new RegExp(`${u}${H}${u}#+ ${b}(?:${T}|${N}).*$`,"gm");a=a==null?void 0:a.replace(c,"").replace(O,""),n=n.replace(new RegExp(this.escapeRegExp(s.link),"g"),`${u}${s.title}${u}${a}${u}`)}else console.warn(`Error fetching linked note content for: ${s.link}`)}catch(a){console.error(a)}return n}));let i=r.map(n=>this.extractRoleAndMessage(n));return{messages:r,messagesWithRole:i}}addSystemCommandsToMessages(e,t){return!t||t.length===0?e:[...t.map(i=>({role:"system",content:i})),...e]}getHeaderRole(e,t,r){return`${u}${H}${u}${e}${b}${t}${r?`<span style="font-size: small;"> (${r})</span>`:""}${u}`}unfinishedCodeBlock(e){let t=e.match(/```/g);return t!==null&&t.length%2!==0}formatMessage(e,t,r){let i=D(t);return`${this.getHeaderRole(i,e.role,r)}${e.content}`}appendMessage(e,t,r){let i=D(r),n=this.getHeaderRole(i,N),o=this.getHeaderRole(i,T);e.replaceRange(`${n}${t}${o}`,e.getCursor())}processResponse(e,t,r){t.mode==="streaming"?t.wasAborted||this.processStreamingResponse(e,r):this.processStandardResponse(e,t,r)}processStreamingResponse(e,t){let r=D(t.headingLevel),i=this.getHeaderRole(r,T);e.replaceRange(i,e.getCursor());let n=e.getCursor(),o={line:n.line,ch:n.ch+i.length};e.setCursor(o)}processStandardResponse(e,t,r){let i=typeof t=="object"&&t.fullString||t,n=typeof t=="object"?t.model:void 0,o=this.unfinishedCodeBlock(i)?i+"\n```":i,s=D(r.headingLevel),a=this.getHeaderRole(s,N,n),c=this.getHeaderRole(s,T);e.replaceRange(`${a}${o}${c}`,e.getCursor())}escapeRegExp(e){return e.replace(/[.*+?^${}()|[\]\\]/g,"\\$&")}};var x=require("obsidian");var k=require("obsidian"),ne=class extends k.SuggestModal{constructor(e,t,r){super(e),this.settings=t,this.titleDate=r}getFilesInChatFolder(){let e=this.app.vault.getAbstractFileByPath(this.settings.chatTemplateFolder);if(e!=null)return e.children;throw new k.Notice(`Error getting folder: ${this.settings.chatTemplateFolder}`),new Error(`Error getting folder: ${this.settings.chatTemplateFolder}`)}getSuggestions(e){let t=this.getFilesInChatFolder();return e==""?t.map(r=>({title:r.basename,file:r})).sort((r,i)=>r.title.localeCompare(i.title)):t.filter(r=>r.basename.toLowerCase().includes(e.toLowerCase())).map(r=>({title:r.basename,file:r})).sort((r,i)=>r.title.localeCompare(i.title))}renderSuggestion(e,t){t.createEl("div",{text:e.title})}async onChooseSuggestion(e,t){new k.Notice(`Selected ${e.title}`);let r=await this.app.vault.read(e.file),i=r;!/^---\n[\s\S]*?\n---/.test(r)&&this.settings.defaultChatFrontmatter&&(i=this.settings.defaultChatFrontmatter+`

`+r);let o=`${this.titleDate} ${e.title}`,s=(0,k.normalizePath)(`${this.settings.chatFolder}/${o}.md`),a=1;for(;await this.app.vault.adapter.exists(s);)s=(0,k.normalizePath)(`${this.settings.chatFolder}/${o} (${a}).md`),a++;try{let c=await this.app.vault.create(s,i);await this.app.workspace.openLinkText(c.basename,"",!0)}catch(c){console.error(c)}}};var B=class{constructor(e,t,r){this.app=e;this.fileService=t;this.editorContentService=r}async createNewChatFromTemplate(e,t){try{if(!e.chatFolder||e.chatFolder.trim()===""){new x.Notice("[ChatGPT MD] No chat folder value found. Please set one in settings.");return}if(!e.chatTemplateFolder||e.chatTemplateFolder.trim()===""){new x.Notice("[ChatGPT MD] No chat template folder value found. Please set one in settings.");return}if(!await this.fileService.ensureFolderExists(e.chatFolder,Ae)||!await this.fileService.ensureFolderExists(e.chatTemplateFolder,$e))return;new ne(this.app,e,t).open()}catch(r){console.error("[ChatGPT MD] Error in Create new chat from template",r),new x.Notice("[ChatGPT MD] Error in Create new chat from template, check console")}}async createNewChatWithHighlightedText(e,t){try{let r=e.getSelection();if(!t.chatFolder||t.chatFolder.trim()===""){new x.Notice("[ChatGPT MD] No chat folder value found. Please set one in settings.");return}if(!await this.fileService.ensureFolderExists(t.chatFolder,Ae))return;let n=`${this.fileService.formatDate(new Date,t.dateFormat)}.md`,o=`${t.chatFolder}/${n}`,s="";t.defaultChatFrontmatter&&(s=t.defaultChatFrontmatter+`

`),r&&(s+=r);let a=await this.fileService.createNewFile(o,s);await this.app.workspace.openLinkText(a.basename,"",!0,{state:{mode:"source"}});let c=this.app.workspace.getActiveViewOfType(x.MarkdownView);if(!c){new x.Notice("No active markdown editor found.");return}c.editor.focus(),this.editorContentService.moveCursorToEnd(c.editor)}catch(r){console.error("[ChatGPT MD] Error in Create new chat with highlighted text",r),new x.Notice("[ChatGPT MD] Error in Create new chat with highlighted text, check console")}}};var Te=require("obsidian");var ze=require("obsidian"),R=class{showNotification(e,t=5e3){new ze.Notice(e,t)}formatChatMessage(e,t=!1){return t?`I am sorry. ${e}`:e}showSuccess(e){this.showNotification(`\u2705 ${e}`,3e3)}showWarning(e){this.showNotification(`\u26A0\uFE0F ${e}`,5e3)}showError(e){this.showNotification(`\u274C ${e}`,7e3)}};function P(l){return!!l&&l.trim()!==""}var v=class{constructor(e){this.notificationService=e||new R}getApiKey(e,t){switch(t){case h:return e.apiKey;case d:return e.openrouterApiKey;case g:return"";case S:return"";default:return""}}validateApiKey(e,t){if(!(t===g||t===S)&&!P(e)){let r=`${t} API key is missing or invalid. Please add your ${t} API key in the settings.`;throw this.notificationService.showError(r),new Error(r)}}createAuthHeaders(e,t){let r={"Content-Type":"application/json"};switch(t){case h:r.Authorization=`Bearer ${e}`;break;case d:r.Authorization=`Bearer ${e}`,r["HTTP-Referer"]="https://github.com/bramses/chatgpt-md",r["X-Title"]="Obsidian ChatGPT MD Plugin";break;case g:break;case S:break}return r}};var w=class{constructor(e){this.collectedCitations=new Set;this.tableBuffer="";this.isInTable=!1;this.tableStartPosition=null;this.notificationService=e||new R}insertAssistantHeader(e,t,r){let i=j(t,N,r),n={line:e.getCursor().line,ch:e.getCursor().ch};e.replaceRange(i,n);let o={line:n.line,ch:n.ch+i.length};return e.setCursor(o),{initialCursor:n,newCursor:o}}parseNonStreamingResponse(e,t){var r,i,n;switch(t){case h:return e.choices[0].message.content;case d:return e.choices[0].message.content;case S:return e.choices[0].message.content;case g:return e.message&&e.message.content?e.message.content:e.response?e.response:JSON.stringify(e);default:return console.warn(`Unknown service type: ${t}`),((n=(i=(r=e==null?void 0:e.choices)==null?void 0:r[0])==null?void 0:i.message)==null?void 0:n.content)||(e==null?void 0:e.response)||JSON.stringify(e)}}processStreamLine(e,t,r,i,n,o){switch(n){case h:case d:case S:return this.processOpenAIFormat(e,t,r,i,o);case g:return this.processOllamaFormat(e,t,r,i,o);default:return console.warn(`Unknown service type for streaming: ${n}`),t}}processOpenAIFormat(e,t,r,i,n){if(e.trim()==="")return t;try{let o=e.substring(5).trimStart(),s=JSON.parse(o);if(s.citations&&s.citations.length>0)for(let a of s.citations)this.collectedCitations.add(a);if(s.choices&&s.choices[0]){let{delta:a}=s.choices[0];if(a&&a.content)return this.processContentWithTableBuffering(a.content,t,r,n)}return t}catch(o){return t}}processOllamaFormat(e,t,r,i,n){if(e.trim()==="")return t;try{let o=JSON.parse(e);if(o.message&&o.message.content){let s=o.message.content;return this.processContentWithTableBuffering(s,t,r,n)}return o.response?this.processContentWithTableBuffering(o.response,t,r,n):t}catch(o){return t}}async processStreamResponse(e,t,r,i,n,o){let s=e.body.getReader(),a=new TextDecoder,c=!1,p="",m=!1;try{for(;!c;){let{value:f,done:F}=await s.read();if(c=F,c)break;let J=a.decode(f).split(`
`);for(let U of J)U.startsWith("data: [DONE]")||(U.startsWith("data:")?p=this.processStreamLine(U,p,r,i.newCursor,t,n):U.trim()!==""&&(p=this.processStreamLine(U,p,r,i.newCursor,t,n)))}}catch(f){}if(o&&o.wasAborted())return m=!0,o.resetAbortedFlag(),this.resetTableState(),n||r.replaceRange("",i.initialCursor,r.getCursor()),{text:"",wasAborted:m};if(this.isInTable&&this.tableBuffer){if(this.tableStartPosition&&!n){let f=r.getCursor();r.replaceRange(this.tableBuffer,this.tableStartPosition,f),r.setCursor({line:this.tableStartPosition.line,ch:this.tableStartPosition.ch+this.tableBuffer.length})}else n&&r.replaceSelection(this.tableBuffer);p+=this.tableBuffer,this.resetTableState()}if(Ye(p)){let f=r.getCursor();r.replaceRange("\n```",f),p+="\n```"}if(this.collectedCitations.size>0){let F=`

**Sources:**
`+Array.from(this.collectedCitations).map((J,U)=>`${U+1}. [${J}](${J})`).join(`
`),I=r.getCursor();r.replaceRange(F,I),r.setCursor({line:I.line,ch:I.ch+F.length}),p+=F,this.collectedCitations.clear()}if(!n){let f=r.getCursor();r.replaceRange("",f,{line:1/0,ch:1/0})}return{text:p,wasAborted:m}}isTableRow(e){let t=e.trim();if(!t.includes("|")||t.length<3||this.isTableSeparator(t))return!1;let r=t.split("|");return r.length>=2&&r.some(i=>i.trim().length>0)}isTableSeparator(e){let t=e.trim();return!t.includes("|")||!t.includes("-")?!1:/^[\|\-\:\s]+$/.test(t)}isTableEnd(e,t){let i=(e+t).split(`
`).filter(n=>n.trim()!=="").pop()||"";return this.isInTable&&!this.isTableRow(i)&&!this.isTableSeparator(i)}isCompleteTable(e){let t=e.split(`
`).filter(o=>o.trim()!=="");if(t.length<2)return!1;let r=!1,i=!1,n=!1;for(let o of t)this.isTableRow(o)?i?n=!0:r=!0:this.isTableSeparator(o)&&(i=!0);return r&&i&&n}resetTableState(){this.isInTable=!1,this.tableBuffer="",this.tableStartPosition=null}processContentWithTableBuffering(e,t,r,i){if(!this.isInTable&&e.includes("|")&&(t.slice(-200)+e).split(`
`).some(c=>{let p=c.trim();return p.includes("|")&&(this.isTableRow(p)||this.isTableSeparator(p))}))return this.isInTable=!0,this.tableBuffer=e,this.tableStartPosition=r.getCursor(),t+e;if(this.isInTable){if(this.tableBuffer+=e,this.shouldFlushTable(this.tableBuffer,e)){let{tableContent:o,remainingContent:s}=this.extractTableFromBuffer(this.tableBuffer);if(this.tableStartPosition&&!i){let a=r.getCursor();r.replaceRange(o,this.tableStartPosition,a),r.setCursor({line:this.tableStartPosition.line,ch:this.tableStartPosition.ch+o.length})}else i&&r.replaceSelection(o);if(this.resetTableState(),s){if(i)r.replaceSelection(s);else{let a=r.getCursor();r.replaceRange(s,a),r.setCursor({line:a.line,ch:a.ch+s.length})}return t+o+s}return t+o}return t+e}if(i)r.replaceSelection(e);else{let n=r.getCursor();r.replaceRange(e,n),r.setCursor({line:n.line,ch:n.ch+e.length})}return t+e}shouldFlushTable(e,t){let r=e.split(`
`);return!!(e.includes(`

`)||this.isCompleteTable(e)&&t.includes(`
`)&&r.slice(-3).filter(a=>a.trim()!=="").some(a=>{let c=a.trim();return c!==""&&!this.isTableRow(c)&&!this.isTableSeparator(c)})||e.length>2e3)}extractTableFromBuffer(e){let r=this.reconstructTableLines(e).split(`
`),i=[],n=[],o=!1;for(let c=0;c<r.length;c++){let p=r[c],m=p.trim();if(!o)if(m===""||this.isTableRow(m)||this.isTableSeparator(m))i.push(p);else{o=!0,n=r.slice(c);break}}let s=i.join(`
`);s&&!s.endsWith(`
`)&&(s+=`
`);let a=n.join(`
`);return{tableContent:s,remainingContent:a}}reconstructTableLines(e){let t=e;return t=t.replace(/\|\|/g,`|
|`),t=t.replace(/\n\n+/g,`
`),t}};var _=class{constructor(e){this.notificationService=e}handleApiError(e,t,r={showNotification:!0,logToConsole:!0,returnForChat:!1}){var m,f,F,I;let i=`[ChatGPT MD] ${t}`,n="unknown_error",o="",s="",a=((m=r.context)==null?void 0:m.model)||"",c=((f=r.context)==null?void 0:f.url)||"",p=this.formatContextInfo(a,c);if(e instanceof Object?e.name==="AbortError"?(n="stream_aborted",o=`${i}: Stream aborted`,s="Stream aborted"):e.message===We?(n="network_error",o=`${i}: Network connection error`,s=Fe):e.status===401||((F=e.error)==null?void 0:F.status)===401?(n="authentication_error",o=`${i}: Authentication failed (401)`,s=Le):e.status===404||((I=e.error)==null?void 0:I.status)===404?(n="not_found_error",o=`${i}: Resource not found (404)${p?` - ${p}`:""}`,s=`${xe}${p?`${u}${p}`:""}`):e.error?(n="api_error",o=`${i}: ${e.error.message}${p?` - ${p}`:""}`,s=`${Z}${u}${e.error.message}${p?`${u}${p}`:""}`):(o=`${i}: ${JSON.stringify(e)}${p?` - ${p}`:""}`,s=`${Z}${u}${JSON.stringify(e)}${p?`${u}${p}`:""}`):(o=`${i}: ${e}${p?` - ${p}`:""}`,s=`${Z}${u}${e}${p?`${u}${p}`:""}`),r.logToConsole&&console.error(o,e,r.context),r.showNotification&&this.notificationService.showNotification(o,5e3),r.returnForChat)return`I am sorry, I could not answer your request because of an error, here is what went wrong-

${e instanceof Object&&e.error?e.error.message:(e==null?void 0:e.message)||e||"undefined"}

Model- ${a}, URL- ${c}`;throw new Error(o)}formatContextInfo(e,t){let r=[];return e&&r.push(`Model: ${e}`),t&&r.push(`URL: ${t}`),r.length>0?r.join(", "):""}handleUrlError(e,t,r){let i=`[ChatGPT MD] Error calling specified URL: ${e}`;return this.notificationService.showNotification(i),console.error(i,{url:e,defaultUrl:t,serviceName:r}),`I am sorry, I could not answer your request because of an error, here is what went wrong-

Error connecting to the custom URL.

Model- ${r===g?"llama2":"unknown"}, URL- ${e}`}handleModelError(e,t){let r=`[ChatGPT MD] Error calling model: ${e}`;return this.notificationService.showNotification(r),console.error(r,{model:e,serviceName:t}),`I am sorry, there was an error with the model: ${e}. Please check your settings or try a different model.`}handleValidationError(e,t){let r=`[ChatGPT MD] Validation Error: ${e}`;throw this.notificationService.showNotification(r),console.error(r,t),new Error(r)}};var y=class{constructor(e,t,r,i){this.abortController=null;this.wasStreamingAborted=!1;this.notificationService=t||new R,this.errorService=e||new _(this.notificationService),this.apiAuthService=r||new v,this.apiResponseParser=i||new w}async makeStreamingRequest(e,t,r,i){try{console.log(`[ChatGPT MD] Making streaming request to ${i}`,t),this.abortController=new AbortController;let n=await fetch(e,{method:"POST",headers:r,body:JSON.stringify(t),signal:this.abortController.signal});if(!n.ok)throw await this.handleHttpError(n,i,t,e);if(!n.body)throw new Error("The response body was empty");return n}catch(n){return this.handleRequestError(n,i,t,e)}}async makeNonStreamingRequest(e,t,r,i){try{console.log(`[ChatGPT MD] Making non-streaming request to ${i}`,t);let o=(await(0,Te.requestUrl)({url:e,method:"POST",headers:r,contentType:"application/json",body:JSON.stringify(t),throw:!1})).json;return o!=null&&o.error?this.errorService.handleApiError({error:o.error},i,{returnForChat:!0,showNotification:!0,context:{model:t.model,url:e}}):this.apiResponseParser.parseNonStreamingResponse(o,i)}catch(n){return this.errorService.handleApiError(n,i,{returnForChat:!0,showNotification:!0,context:{model:t.model,url:e}})}}async makeGetRequest(e,t,r){try{console.log(`[ChatGPT MD] Making GET request to ${r}`);let i=await(0,Te.requestUrl)({url:e,method:"GET",headers:t,throw:!1});if(i.status!==200)throw new Error(`Failed to fetch data from ${e}: ${i.status}`);return i.json}catch(i){throw console.error(`Error making GET request to ${r}:`,i),i}}async handleHttpError(e,t,r,i){let n;try{n=await e.json()}catch(s){n={status:e.status,statusText:e.statusText}}let o=this.errorService.handleApiError(n,t,{returnForChat:!1,showNotification:!0,context:{model:r.model,url:i,status:e.status}});return new Error(o)}handleRequestError(e,t,r,i){return this.errorService.handleApiError(e,t,{returnForChat:!1,showNotification:!0,context:{model:r.model,url:i}})}stopStreaming(){this.abortController&&(this.wasStreamingAborted=!0,this.abortController.abort(),this.abortController=null)}wasAborted(){return this.wasStreamingAborted}resetAbortedFlag(){this.wasStreamingAborted=!1}};var L=class{constructor(e,t){this.inferTitleFromMessages=async(e,t,r)=>{try{if(t.length<2)return this.notificationService.showWarning("Not enough messages to infer title. Minimum 2 messages."),"";let i=`Infer title from the summary of the content of these messages. The title **cannot** contain any of the following characters: colon (:), back slash (\\), forward slash (/), asterisk (*), question mark (?), double quote ("), less than (<), greater than (>), or pipe (|) as these are invalid in file names. Just return the title. Write the title in ${r.inferTitleLanguage}. 
Messages:${u}${JSON.stringify(t)}`,n=this.getDefaultConfig(),o={...n,...r};o.model||(console.log("[ChatGPT MD] Model not set for title inference, using default model"),o.model=n.model),o.url||(console.log("[ChatGPT MD] URL not set for title inference, using default URL"),o.url=n.url),console.log("[ChatGPT MD] Inferring title with model:",o.model);try{return await this.callNonStreamingAPIForTitleInference(e,[{role:T,content:i}],o)}catch(s){return console.error("[ChatGPT MD] Error calling API for title inference:",s),""}}catch(i){return console.error("[ChatGPT MD] Error inferring title:",i),this.showNoTitleInferredNotification(),""}};this.notificationService=t!=null?t:new R,this.errorService=e!=null?e:new _(this.notificationService),this.apiService=new y(this.errorService,this.notificationService),this.apiAuthService=new v(this.notificationService),this.apiResponseParser=new w(this.notificationService)}async callAIAPI(e,t={},r,i,n,o,s,a){let c={...this.getDefaultConfig(),...t};return a&&(c.url=i),t.stream&&n?this.callStreamingAPI(s,e,c,n,r,o):this.callNonStreamingAPI(s,e,c)}async inferTitle(e,t,r,i){try{if(!e.file)throw new Error("No active file found");let n=this.getApiKeyFromSettings(t),o=await this.inferTitleFromMessages(n,r,t),s="";return typeof o=="string"?s=o:o&&typeof o=="object"&&(s=o.fullString||""),s&&s.trim().length>0?(await i.writeInferredTitle(e,s.trim()),s.trim()):(this.showNoTitleInferredNotification(),"")}catch(n){return console.error("[ChatGPT MD] Error in inferTitle:",n),this.showNoTitleInferredNotification(),""}}showNoTitleInferredNotification(){var e;(e=this.notificationService)==null||e.showWarning("Could not infer title. The file name was not changed.")}async callNonStreamingAPIForTitleInference(e,t,r){try{r.stream=!1;let{payload:i,headers:n}=this.prepareApiCall(e,t,r,!0);return await this.apiService.makeNonStreamingRequest(this.getApiEndpoint(r),i,n,this.serviceType)}catch(i){throw i}}stopStreaming(){var e;(e=this.apiService)==null||e.stopStreaming()}processStreamingResult(e){return e.wasAborted&&e.text===""?{fullString:"",mode:"streaming",wasAborted:!0}:{fullString:e.text,mode:"streaming",wasAborted:e.wasAborted}}getApiEndpoint(e){return`${e.url}${Re[this.serviceType]}`}addPluginSystemMessage(e){return[{role:qe,content:re},...e]}prepareApiCall(e,t,r,i=!1){this.apiAuthService.validateApiKey(e,this.serviceType);let n=i?t:this.addPluginSystemMessage(t),o=this.createPayload(r,n),s=this.apiAuthService.createAuthHeaders(e,this.serviceType);return{payload:o,headers:s}}handleApiCallError(e,t,r=!1){if(console.error(`[ChatGPT MD] ${this.serviceType} API error:`,e),!!r)throw e;return this.errorService.handleApiError(e,this.serviceType,{returnForChat:!0,showNotification:!0,context:{model:t.model,url:t.url}})}},Je=(l,e)=>{if(e!=null&&e.includes(d))return d;if(e!=null&&e.startsWith("lmstudio@"))return S;if(e!=null&&e.includes("local"))return l!=null&&l.includes("1234")?S:g;let t="openrouter",r=["localhost","127.0.0.1"],i="1234";if(l!=null&&l.includes(t))return d;if(l!=null&&l.includes(i))return S;if(r.some(n=>l==null?void 0:l.includes(n)))return g},Xe=l=>{let e=P(l.openrouterApiKey),t=P(l.apiKey);return t&&e?h:e?d:t?h:null};var A={aiService:h,frequency_penalty:0,max_tokens:300,model:"gpt-4",presence_penalty:0,stream:!0,system_commands:null,tags:[],temperature:1,title:"Untitled",top_p:1,url:"https://api.openai.com"},Ze=async(l,e)=>{try{let t=new v;if(!P(e))return console.error("OpenAI API key is missing. Please add your OpenAI API key in the settings."),[];let r=new y,i=t.createAuthHeaders(e,h);return(await r.makeGetRequest(`${l}/v1/models`,i,h)).data.filter(o=>(o.id.includes("o3")||o.id.includes("o4")||o.id.includes("o1")||o.id.includes("gpt-4")||o.id.includes("gpt-3"))&&!o.id.includes("audio")&&!o.id.includes("transcribe")&&!o.id.includes("realtime")&&!o.id.includes("o1-pro")&&!o.id.includes("tts")).sort((o,s)=>o.id<s.id?1:o.id>s.id?-1:0).map(o=>o.id)}catch(t){return console.error("Error fetching models:",t),[]}},oe=class extends L{constructor(t,r,i,n,o){super(t,r);this.serviceType=h;this.errorService=t||new _(this.notificationService),this.apiService=i||new y(this.errorService,this.notificationService),this.apiAuthService=n||new v(this.notificationService),this.apiResponseParser=o||new w(this.notificationService)}getDefaultConfig(){return A}getApiKeyFromSettings(t){return this.apiAuthService.getApiKey(t,h)}createPayload(t,r){let i=t.model.includes("@")?t.model.split("@")[1]:t.model,n=r;if(t.system_commands&&t.system_commands.length>0){let s=t.system_commands.map(a=>({role:ee,content:a}));n=[...s,...r],console.log(`[ChatGPT MD] Added ${s.length} developer commands to messages`)}let o={model:i,messages:n,max_completion_tokens:t.max_tokens,stream:t.stream};return i.includes("search")||(o.temperature=t.temperature,o.top_p=t.top_p,o.presence_penalty=t.presence_penalty,o.frequency_penalty=t.frequency_penalty),o}handleAPIError(t,r,i){let n={model:r.model,url:r.url,defaultUrl:A.url,aiService:h};return t instanceof Object&&r.url!==A.url?this.errorService.handleUrlError(r.url,A.url,h):this.errorService.handleApiError(t,h,{context:n,showNotification:!0,logToConsole:!0})}async callStreamingAPI(t,r,i,n,o,s){try{let{payload:a,headers:c}=this.prepareApiCall(t,r,i),p=this.apiResponseParser.insertAssistantHeader(n,o,a.model),m=await this.apiService.makeStreamingRequest(this.getApiEndpoint(i),a,c,this.serviceType),f=await this.apiResponseParser.processStreamResponse(m,this.serviceType,n,p,s,this.apiService);return this.processStreamingResult(f)}catch(a){return{fullString:`Error: ${a}`,mode:"streaming"}}}async callNonStreamingAPI(t,r,i){var n;try{console.log('[ChatGPT MD] "no stream"',i),i.stream=!1;let{payload:o,headers:s}=this.prepareApiCall(t,r,i);return{fullString:await this.apiService.makeNonStreamingRequest(this.getApiEndpoint(i),o,s,this.serviceType),model:o.model}}catch(o){let s=r.length===1&&((n=r[0].content)==null?void 0:n.toString().includes("Infer title from the summary"));return this.handleApiCallError(o,i,s)}}showNoTitleInferredNotification(){this.notificationService.showWarning("Could not infer title. The file name was not changed.")}addPluginSystemMessage(t){return[{role:ee,content:re},...t]}};var M={aiService:g,model:"llama2",url:"http://localhost:11434",stream:!0,title:"Untitled",system_commands:null},Qe=async l=>{try{let e=new y,t={"Content-Type":"application/json"};return(await e.makeGetRequest(`${l}/api/tags`,t,g)).models.sort((n,o)=>n.name<o.name?1:n.name>o.name?-1:0).map(n=>`local@${n.name}`)}catch(e){return console.error("Error fetching models:",e),[]}},se=class extends L{constructor(t,r,i,n,o){super(t,r);this.serviceType=g;this.errorService=t||new _(this.notificationService),this.apiService=i||new y(this.errorService,this.notificationService),this.apiAuthService=n||new v(this.notificationService),this.apiResponseParser=o||new w(this.notificationService)}getDefaultConfig(){return M}getApiKeyFromSettings(t){return this.apiAuthService.getApiKey(t,g)}createPayload(t,r){let i=t.model.includes("@")?t.model.split("@")[1]:t.model,n=r;if(t.system_commands&&t.system_commands.length>0){let o=t.system_commands.map(s=>({role:"system",content:s}));n=[...o,...r],console.log(`[ChatGPT MD] Added ${o.length} system commands to messages`)}return{model:i,messages:n,stream:t.stream}}handleAPIError(t,r,i){let n={model:r.model,url:r.url,defaultUrl:M.url,aiService:g};return t instanceof Object&&r.url!==M.url?this.errorService.handleUrlError(r.url,M.url,g):this.errorService.handleApiError(t,g,{context:n,showNotification:!0,logToConsole:!0})}async callStreamingAPI(t,r,i,n,o,s){try{let{payload:a,headers:c}=this.prepareApiCall(t,r,i),p=this.apiResponseParser.insertAssistantHeader(n,o,a.model),m=await this.apiService.makeStreamingRequest(this.getApiEndpoint(i),a,c,this.serviceType),f=await this.apiResponseParser.processStreamResponse(m,this.serviceType,n,p,s,this.apiService);return this.processStreamingResult(f)}catch(a){return console.error("[ChatGPT MD] Ollama streaming error:",a),{fullString:`Error: ${a}`,mode:"streaming"}}}async callNonStreamingAPI(t,r,i){var n;try{console.log('[ChatGPT MD] "no stream"',i),i.stream=!1;let{payload:o,headers:s}=this.prepareApiCall(t,r,i);return{fullString:await this.apiService.makeNonStreamingRequest(this.getApiEndpoint(i),o,s,this.serviceType),model:o.model}}catch(o){let s=r.length===1&&((n=r[0].content)==null?void 0:n.toString().includes("Infer title from the summary"));return this.handleApiCallError(o,i,s)}}showNoTitleInferredNotification(){this.notificationService.showWarning("Could not infer title. The file name was not changed.")}};var C={aiService:d,frequency_penalty:.5,max_tokens:300,model:"anthropic/claude-3-opus:beta",openrouterApiKey:"",presence_penalty:.5,stream:!0,system_commands:null,tags:[],temperature:.3,title:"Untitled",top_p:1,url:"https://openrouter.ai"},et=async(l,e)=>{try{let t=new v;if(!P(e))return console.error("OpenRouter API key is missing. Please add your OpenRouter API key in the settings."),[];let r=new y,i=t.createAuthHeaders(e,d);return(await r.makeGetRequest(`${l}/api/v1/models`,i,d)).data.sort((o,s)=>o.id<s.id?1:o.id>s.id?-1:0).map(o=>`${d}@${o.id}`)}catch(t){return console.error("Error fetching models:",t),[]}},ae=class extends L{constructor(t,r,i,n,o){super(t,r);this.serviceType=d;this.errorService=t||new _(this.notificationService),this.apiService=i||new y(this.errorService,this.notificationService),this.apiAuthService=n||new v(this.notificationService),this.apiResponseParser=o||new w(this.notificationService)}getDefaultConfig(){return C}getApiKeyFromSettings(t){return this.apiAuthService.getApiKey(t,d)}createPayload(t,r){let i=t.model.includes("@")?t.model.split("@")[1]:t.model,n=r;if(t.system_commands&&t.system_commands.length>0){let o=t.system_commands.map(s=>({role:"system",content:s}));n=[...o,...r],console.log(`[ChatGPT MD] Added ${o.length} system commands to messages`)}return{model:i,messages:n,max_tokens:t.max_tokens,temperature:t.temperature,top_p:t.top_p,presence_penalty:t.presence_penalty,frequency_penalty:t.frequency_penalty,stream:t.stream}}handleAPIError(t,r,i){let n={model:r.model,url:r.url,defaultUrl:C.url,aiService:d};return t instanceof Object&&r.url!==C.url?this.errorService.handleUrlError(r.url,C.url,d):this.errorService.handleApiError(t,d,{context:n,showNotification:!0,logToConsole:!0})}async callStreamingAPI(t,r,i,n,o,s){try{let{payload:a,headers:c}=this.prepareApiCall(t,r,i),p=this.apiResponseParser.insertAssistantHeader(n,o,a.model),m=await this.apiService.makeStreamingRequest(this.getApiEndpoint(i),a,c,this.serviceType),f=await this.apiResponseParser.processStreamResponse(m,this.serviceType,n,p,s,this.apiService);return this.processStreamingResult(f)}catch(a){return{fullString:`Error: ${a}`,mode:"streaming"}}}async callNonStreamingAPI(t,r,i){var n;try{console.log('[ChatGPT MD] "no stream"',i),i.stream=!1;let{payload:o,headers:s}=this.prepareApiCall(t,r,i);return{fullString:await this.apiService.makeNonStreamingRequest(this.getApiEndpoint(i),o,s,this.serviceType),model:o.model}}catch(o){let s=r.length===1&&((n=r[0].content)==null?void 0:n.toString().includes("Infer title from the summary"));return this.handleApiCallError(o,i,s)}}showNoTitleInferredNotification(){this.notificationService.showWarning("Could not infer title. The file name was not changed.")}};var E={aiService:S,frequency_penalty:0,max_tokens:300,model:"local-model",presence_penalty:0,stream:!0,system_commands:null,tags:[],temperature:1,title:"Untitled",top_p:1,url:"http://localhost:1234"},tt=async(l,e)=>{try{let t=new v,r=e&&P(e)?t.createAuthHeaders(e,S):{"Content-Type":"application/json"};return(await new y().makeGetRequest(`${l}/v1/models`,r,S)).data.filter(o=>!o.id.includes("embedding")&&!o.id.includes("audio")&&!o.id.includes("transcribe")&&!o.id.includes("tts")).sort((o,s)=>o.id<s.id?1:o.id>s.id?-1:0).map(o=>`lmstudio@${o.id}`)}catch(t){return console.error("Error fetching LM Studio models:",t),[]}},le=class extends L{constructor(t,r,i,n,o){super(t,r);this.serviceType=S;this.errorService=t||new _(this.notificationService),this.apiService=i||new y(this.errorService,this.notificationService),this.apiAuthService=n||new v(this.notificationService),this.apiResponseParser=o||new w(this.notificationService)}getDefaultConfig(){return E}getApiKeyFromSettings(t){return""}createPayload(t,r){let i=t.model.includes("@")?t.model.split("@")[1]:t.model,n=r;if(t.system_commands&&t.system_commands.length>0){let s=t.system_commands.map(a=>({role:"system",content:a}));n=[...s,...r],console.log(`[ChatGPT MD] Added ${s.length} system commands to messages`)}return{model:i,messages:n,max_completion_tokens:t.max_tokens,stream:t.stream,temperature:t.temperature,top_p:t.top_p,presence_penalty:t.presence_penalty,frequency_penalty:t.frequency_penalty}}handleAPIError(t,r,i){let n={model:r.model,url:r.url,defaultUrl:E.url,aiService:S};return t instanceof Object&&r.url!==E.url?this.errorService.handleUrlError(r.url,E.url,S):this.errorService.handleApiError(t,S,{context:n,showNotification:!0,logToConsole:!0})}async callStreamingAPI(t,r,i,n,o,s){try{let{payload:a,headers:c}=this.prepareApiCall(t,r,i),p=this.apiResponseParser.insertAssistantHeader(n,o,a.model),m=await this.apiService.makeStreamingRequest(this.getApiEndpoint(i),a,c,this.serviceType),f=await this.apiResponseParser.processStreamResponse(m,this.serviceType,n,p,s,this.apiService);return this.processStreamingResult(f)}catch(a){return{fullString:`Error: ${a}`,mode:"streaming"}}}async callNonStreamingAPI(t,r,i){var n;try{console.log('[ChatGPT MD] "no stream"',i),i.stream=!1;let{payload:o,headers:s}=this.prepareApiCall(t,r,i);return{fullString:await this.apiService.makeNonStreamingRequest(this.getApiEndpoint(i),o,s,this.serviceType),model:o.model}}catch(o){let s=r.length===1&&((n=r[0].content)==null?void 0:n.toString().includes("Infer title from the summary"));return this.handleApiCallError(o,i,s)}}showNoTitleInferredNotification(){this.notificationService.showWarning("Could not infer title. The file name was not changed.")}};var W=class{constructor(e){this.app=e}getFrontmatter(e,t){let i=e.editor.getValue().match(O),n=i?ie(i[0]):{},o=t.defaultChatFrontmatter?ie(t.defaultChatFrontmatter):{},s={...t,...o,...n},a=s.aiService||Je(s.url,s.model)||Xe(s)||h;return{...{[h]:A,[g]:M,[d]:C,[S]:E}[a]||A,...t,...o,...n,aiService:a}}updateFrontmatterField(e,t,r){let i=e.getValue(),n=i.match(O),o;if(n){let a=n[0].replace(/---/g,""),c=new RegExp(`^${t}:\\s*(.*)$`,"m");c.test(a)?a=a.replace(c,`${t}: ${r}`):a+=`
${t}: ${r}`,o=i.replace(O,`---${a}---`)}else o=`---
${t}: ${r}
---
${i}`;e.setValue(o)}objectToYamlFrontmatter(e){return`---
${Object.entries(e).map(([r,i])=>i==null?`${r}:`:typeof i=="string"?`${r}: "${i}"`:`${r}: ${i}`).join(`
`)}
---

`}generateFrontmatter(e,t={}){if(e.defaultChatFrontmatter){if(Object.keys(t).length>0){let o={...ie(e.defaultChatFrontmatter),...t};return this.objectToYamlFrontmatter(o)}return e.defaultChatFrontmatter+`

`}let r=t.aiService||h,i={stream:e.stream,...t};switch(r){case h:i={...i,model:A.model,temperature:A.temperature,top_p:A.top_p,max_tokens:A.max_tokens,presence_penalty:A.presence_penalty,frequency_penalty:A.frequency_penalty};break;case g:i={...i,model:M.model,url:M.url};break;case d:i={...i,model:C.model,temperature:C.temperature,top_p:C.top_p,max_tokens:C.max_tokens,presence_penalty:C.presence_penalty,frequency_penalty:C.frequency_penalty};break;case S:i={...i,model:E.model,url:E.url,temperature:E.temperature,top_p:E.top_p,max_tokens:E.max_tokens,presence_penalty:E.presence_penalty,frequency_penalty:E.frequency_penalty};break}return this.objectToYamlFrontmatter(i)}};var ce=class{constructor(e,t,r,i,n,o){this.app=e;this.fileService=t||new G(e),this.editorContentService=r||new V;let s=new R;this.messageService=i||new K(this.fileService,s),this.frontmatterService=o||new W(e),this.templateService=n||new B(e,this.fileService,this.editorContentService)}async writeInferredTitle(e,t){return this.fileService.writeInferredTitle(e,t)}async ensureFolderExists(e,t){return this.fileService.ensureFolderExists(e,t)}getDate(e,t){return this.fileService.formatDate(e,t)}addHorizontalRule(e,t,r){this.editorContentService.addHorizontalRule(e,t,r)}clearChat(e){this.editorContentService.clearChat(e)}moveCursorToEnd(e){this.editorContentService.moveCursorToEnd(e)}async getMessagesFromEditor(e,t){return this.messageService.getMessagesFromEditor(e,t)}async createNewChatFromTemplate(e,t){return this.templateService.createNewChatFromTemplate(e,t)}async createNewChatWithHighlightedText(e,t){return this.templateService.createNewChatWithHighlightedText(e,t)}getFrontmatter(e,t,r){return this.frontmatterService.getFrontmatter(e,t)}processResponse(e,t,r){this.messageService.processResponse(e,t,r)}setModel(e,t){this.frontmatterService.updateFrontmatterField(e,"model",t)}};var _e={apiKey:"",openrouterApiKey:"",openaiUrl:A.url,openrouterUrl:C.url,ollamaUrl:M.url,lmstudioUrl:E.url,chatFolder:"ChatGPT_MD/chats",chatTemplateFolder:"ChatGPT_MD/templates",stream:!0,generateAtCursor:!1,autoInferTitle:!1,dateFormat:Q,headingLevel:Ve,inferTitleLanguage:Ke,defaultChatFrontmatter:te};var me=require("obsidian");var pe=class extends me.PluginSettingTab{constructor(e,t,r){super(e,t),this.settingsProvider=r}display(){let{containerEl:e}=this;e.empty();let t=[{id:"apiKey",name:"OpenAI API Key",description:"API Key for OpenAI",type:"text",placeholder:"your openAI API Key",group:"API Keys"},{id:"openrouterApiKey",name:"OpenRouter.ai API Key",description:"API Key for OpenRouter.ai",type:"text",placeholder:"your openRouter API Key",group:"API Keys"},{id:"openaiUrl",name:"OpenAI API URL",description:`URL for OpenAI API
Default URL: ${A.url}`,type:"text",placeholder:A.url,group:"Service URLs"},{id:"openrouterUrl",name:"OpenRouter.ai API URL",description:`URL for OpenRouter.ai API
Default URL: ${C.url}`,type:"text",placeholder:C.url,group:"Service URLs"},{id:"ollamaUrl",name:"Ollama API URL",description:`URL for Ollama API
Default URL: ${M.url}`,type:"text",placeholder:M.url,group:"Service URLs"},{id:"lmstudioUrl",name:"LM Studio API URL",description:`URL for LM Studio API
Default URL: ${E.url}`,type:"text",placeholder:E.url,group:"Service URLs"},{id:"defaultChatFrontmatter",name:"Default Chat Frontmatter",description:"Default frontmatter for new chat files. You can change/use all of the settings exposed by the OpenAI API here: https://platform.openai.com/docs/api-reference/chat/create",type:"textarea",placeholder:te,group:"Chat Behavior"},{id:"stream",name:"Stream",description:"Stream responses from OpenAI",type:"toggle",group:"Chat Behavior"},{id:"generateAtCursor",name:"Generate at Cursor",description:"Generate text at cursor instead of end of file",type:"toggle",group:"Chat Behavior"},{id:"autoInferTitle",name:"Automatically Infer Title",description:"Automatically infer title after 4 messages have been exchanged",type:"toggle",group:"Chat Behavior"},{id:"chatFolder",name:"Chat Folder",description:"Path to folder for chat files",type:"text",group:"Folders"},{id:"chatTemplateFolder",name:"Chat Template Folder",description:"Path to folder for chat file templates",type:"text",placeholder:"chat-templates",group:"Folders"},{id:"dateFormat",name:"Date Format",description:"Date format for chat files. Valid date blocks are: YYYY, MM, DD, hh, mm, ss",type:"text",placeholder:Q,group:"Formatting"},{id:"headingLevel",name:"Heading Level",description:`Heading level for messages (example for heading level 2: '## ${b}${T}'). Valid heading levels are 0, 1, 2, 3, 4, 5, 6`,type:"text",group:"Formatting"},{id:"inferTitleLanguage",name:"Infer title language",description:"Language to use for title inference.",type:"dropdown",options:{English:"English",Japanese:"Japanese",Spanish:"Spanish",French:"French",German:"German",Chinese:"Chinese",Korean:"Korean",Italian:"Italian",Russian:"Russian"},group:"Formatting"}],r={};t.forEach(i=>{r[i.group]||(r[i.group]=[]),r[i.group].push(i)}),Object.entries(r).forEach(([i,n])=>{e.createEl("h3",{text:i}),n.forEach(o=>{this.createSettingElement(e,o)}),e.createEl("hr")})}createSettingElement(e,t){let r=new me.Setting(e).setName(t.name).setDesc(t.description);t.type==="text"?r.addText(i=>(i.setPlaceholder(t.placeholder||"").setValue(String(this.settingsProvider.settings[t.id])).onChange(async n=>{this.settingsProvider.settings[t.id]=n,await this.settingsProvider.saveSettings()}),i.inputEl.style.width="300px",i)):t.type==="textarea"?r.addTextArea(i=>(i.setPlaceholder(t.placeholder||"").setValue(String(this.settingsProvider.settings[t.id]||t.placeholder)).onChange(async n=>{this.settingsProvider.settings[t.id]=n,await this.settingsProvider.saveSettings()}),i.inputEl.style.width="300px",t.id==="defaultChatFrontmatter"&&(i.inputEl.style.height="260px",i.inputEl.style.minHeight="260px"),i)):t.type==="toggle"?r.addToggle(i=>i.setValue(!!this.settingsProvider.settings[t.id]).onChange(async n=>{this.settingsProvider.settings[t.id]=n,await this.settingsProvider.saveSettings()})):t.type==="dropdown"&&t.options&&r.addDropdown(i=>(i.addOptions(t.options||{}),i.setValue(String(this.settingsProvider.settings[t.id])),i.onChange(async n=>{this.settingsProvider.settings[t.id]=n,await this.settingsProvider.saveSettings()}),i.selectEl.style.width="300px",i))}};var de=class{constructor(e,t=new R,r=new _(new R)){this.plugin=e;this.notificationService=t;this.errorService=r;this.settings=structuredClone(_e),this.loadSettings().catch(i=>this.notificationService.showError("Failed to load settings"))}getSettings(){return this.settings}async migrateSettings(){let e=[{setting:"ollamaUrl",pattern:/\/api\/$/,replacement:"",description:"Removing trailing /api/ from Ollama URL",introducedIn:"2.1.3"},{setting:"openrouterUrl",pattern:/\/api\/$/,replacement:"",description:"Removing trailing /api/ from OpenRouter URL",introducedIn:"2.1.3"},{setting:"openaiUrl",pattern:/\/$/,replacement:"",description:"Removing trailing slash from OpenAI URL",introducedIn:"2.1.3"}],t=!1;for(let r of e){let i=r.setting,n=this.settings[i];n&&r.pattern.test(n)&&(this.updateSettings({[i]:n.replace(r.pattern,r.replacement)}),console.log(`[ChatGPT MD] Migration (${r.introducedIn}): ${r.description}`),t=!0)}t&&(await this.saveSettings(),console.log("[ChatGPT MD] Migrated settings"))}async loadSettings(){let e=await this.plugin.loadData();return Object.assign(this.settings,_e,e),this.settings}async saveSettings(){await this.plugin.saveData(this.settings)}updateSettings(e){Object.assign(this.settings,e)}async addSettingTab(){await this.loadSettings(),this.plugin.addSettingTab(new pe(this.plugin.app,this.plugin,{settings:this.settings,saveSettings:this.saveSettings.bind(this)}))}};var he=class{constructor(e,t){this.app=e,this.plugin=t,this.initializeServices()}initializeServices(){this.notificationService=new R,this.errorService=new _(this.notificationService),this.apiService=new y(this.errorService,this.notificationService),this.apiAuthService=new v(this.notificationService),this.apiResponseParser=new w(this.notificationService),this.fileService=new G(this.app),this.editorContentService=new V,this.messageService=new K(this.fileService,this.notificationService),this.frontmatterService=new W(this.app),this.templateService=new B(this.app,this.fileService,this.editorContentService),this.editorService=new ce(this.app,this.fileService,this.editorContentService,this.messageService,this.templateService,this.frontmatterService),this.settingsService=new de(this.plugin,this.notificationService,this.errorService)}getAiApiService(e){switch(e){case h:return new oe(this.errorService,this.notificationService,this.apiService,this.apiAuthService,this.apiResponseParser);case g:return new se(this.errorService,this.notificationService,this.apiService,this.apiAuthService,this.apiResponseParser);case d:return new ae(this.errorService,this.notificationService,this.apiService,this.apiAuthService,this.apiResponseParser);case S:return new le(this.errorService,this.notificationService,this.apiService,this.apiAuthService,this.apiResponseParser);default:throw new Error(`Unknown AI service type: ${e}`)}}getFileService(){return this.fileService}getEditorContentService(){return this.editorContentService}getMessageService(){return this.messageService}getTemplateService(){return this.templateService}getFrontmatterService(){return this.frontmatterService}getEditorService(){return this.editorService}getNotificationService(){return this.notificationService}getErrorService(){return this.errorService}getApiService(){return this.apiService}getApiAuthService(){return this.apiAuthService}getApiResponseParser(){return this.apiResponseParser}getSettingsService(){return this.settingsService}};var $=require("obsidian");var ge=require("obsidian"),z=class extends ge.SuggestModal{constructor(e,t,r,i=[]){super(e),this.modelNames=i,this.editor=t,this.editorService=r,this.limit=this.modelNames.length,this.modelNames.length>0?this.setPlaceholder("Select Large Language Model"):this.setPlaceholder("Loading available models...")}getSuggestions(e){return this.modelNames.filter(t=>t.toLowerCase().includes(e.toLowerCase()))}renderSuggestion(e,t){t.createEl("div",{text:e})}onChooseSuggestion(e,t){this.modelNames.indexOf(e)===-1||this.modelNames.length===0||(new ge.Notice(`Selected model: ${e}`),this.editorService.setModel(this.editor,e))}};var ue=class{constructor(e,t,r){this.aiService=null;this.availableModels=[];this.plugin=e,this.serviceLocator=t,this.settingsService=r,this.statusBarItemEl=e.addStatusBarItem(),this.apiAuthService=new v}registerCommands(){this.registerChatCommand(),this.registerSelectModelCommand(),this.registerAddDividerCommand(),this.registerAddCommentBlockCommand(),this.registerStopStreamingCommand(),this.registerInferTitleCommand(),this.registerMoveToNewChatCommand(),this.registerChooseChatTemplateCommand(),this.registerClearChatCommand()}registerChatCommand(){this.plugin.addCommand({id:Pe,name:"Chat",icon:"message-circle",editorCallback:async(e,t)=>{var o;let r=this.serviceLocator.getEditorService(),i=this.settingsService.getSettings(),n=r.getFrontmatter(t,i,this.plugin.app);this.aiService=this.serviceLocator.getAiApiService(n.aiService);try{let{messagesWithRole:s,messages:a}=await r.getMessagesFromEditor(e,i);i.generateAtCursor||r.moveCursorToEnd(e),$.Platform.isMobile?new $.Notice(`[ChatGPT MD] Calling ${n.model}`):this.updateStatusBar(`Calling ${n.model}`);let c=this.apiAuthService.getApiKey(i,n.aiService),p=await this.aiService.callAIAPI(s,n,D(i.headingLevel),this.getAiApiUrls(n)[n.aiService],e,i.generateAtCursor,c,i);if(r.processResponse(e,p,i),i.autoInferTitle&&je((o=t==null?void 0:t.file)==null?void 0:o.basename,i.dateFormat)&&s.length>Be){let m={...n,openrouterApiKey:this.apiAuthService.getApiKey(i,d),url:this.getAiApiUrls(n)[n.aiService]};m.model||(console.log("[ChatGPT MD] Model not set for auto title inference, using default model"),n.aiService===h?m.model="gpt-4":n.aiService===g?m.model="llama2":n.aiService===d?m.model="anthropic/claude-3-opus:beta":n.aiService===S&&(m.model="local-model")),console.log("[ChatGPT MD] Auto-inferring title with settings:",{aiService:n.aiService,model:m.model}),await this.aiService.inferTitle(t,m,a,r)}}catch(s){$.Platform.isMobile&&new $.Notice(`[ChatGPT MD] Calling ${n.model}. `+s,9e3),console.log(s)}this.updateStatusBar("")}})}registerSelectModelCommand(){this.plugin.addCommand({id:"select-model-command",name:"Select Model",icon:"list",editorCallback:async(e,t)=>{let r=this.serviceLocator.getEditorService(),i=this.settingsService.getSettings(),n=new z(this.plugin.app,e,r,this.availableModels);n.open(),(async()=>{try{let o=r.getFrontmatter(t,i,this.plugin.app),s=this.apiAuthService.getApiKey(i,h),a=this.apiAuthService.getApiKey(i,d),c={[h]:o.openaiUrl||i.openaiUrl||A.url,[d]:o.openrouterUrl||i.openrouterUrl||C.url,[g]:o.ollamaUrl||i.ollamaUrl||M.url,[S]:o.lmstudioUrl||i.lmstudioUrl||E.url},p=await this.fetchAvailableModels(c,s,a),m=new Set(this.availableModels),f=new Set(p);(this.availableModels.length!==p.length||![...m].every(I=>f.has(I))||![...f].every(I=>m.has(I)))&&p.length>0&&(console.log("[ChatGPT MD] Models updated. Refreshing modal."),this.availableModels=p,n.close(),new z(this.plugin.app,e,r,this.availableModels).open())}catch(o){console.error("[ChatGPT MD] Error fetching fresh models in background:",o)}})()}})}registerAddDividerCommand(){this.plugin.addCommand({id:we,name:"Add divider",icon:"minus",editorCallback:async(e,t)=>{let r=this.serviceLocator.getEditorService(),i=this.settingsService.getSettings();r.addHorizontalRule(e,T,i.headingLevel)}})}registerAddCommentBlockCommand(){this.plugin.addCommand({id:Me,name:"Add comment block",icon:"comment",editorCallback:(e,t)=>{let r=e.getCursor(),i=r.line,n=r.ch,o=`${Ge}${u}${He}`;e.replaceRange(o,r);let s={line:i+1,ch:n};e.setCursor(s)}})}registerStopStreamingCommand(){this.plugin.addCommand({id:Ie,name:"Stop streaming",icon:"octagon",callback:()=>{this.aiService&&"stopStreaming"in this.aiService?this.aiService.stopStreaming():this.serviceLocator.getNotificationService().showWarning("No active streaming request to stop")}})}registerInferTitleCommand(){this.plugin.addCommand({id:Oe,name:"Infer title",icon:"subtitles",editorCallback:async(e,t)=>{let r=this.serviceLocator.getEditorService(),i=this.settingsService.getSettings(),n=r.getFrontmatter(t,i,this.plugin.app);if(this.aiService=this.serviceLocator.getAiApiService(n.aiService),!n.model){console.log("[ChatGPT MD] Model not set in frontmatter, using default model");return}this.updateStatusBar(`Calling ${n.model}`);let{messages:o}=await r.getMessagesFromEditor(e,i),s={...i,...n,openrouterApiKey:this.apiAuthService.getApiKey(i,d),url:this.getAiApiUrls(n)[n.aiService]};await this.aiService.inferTitle(t,s,o,r),this.updateStatusBar("")}})}registerMoveToNewChatCommand(){this.plugin.addCommand({id:be,name:"Create new chat with highlighted text",icon:"highlighter",editorCallback:async(e,t)=>{let r=this.serviceLocator.getEditorService(),i=this.settingsService.getSettings();try{await r.createNewChatWithHighlightedText(e,i)}catch(n){console.error("[ChatGPT MD] Error in Create new chat with highlighted text",n),new $.Notice("[ChatGPT MD] Error in Create new chat with highlighted text, check console")}}})}registerChooseChatTemplateCommand(){this.plugin.addCommand({id:Ne,name:"Create new chat from template",icon:"layout-template",callback:async()=>{let e=this.serviceLocator.getEditorService(),t=this.settingsService.getSettings();if(t.dateFormat){await e.createNewChatFromTemplate(t,e.getDate(new Date,t.dateFormat));return}new $.Notice("date format cannot be empty in your ChatGPT MD settings. You can choose something like YYYYMMDDhhmmss")}})}registerClearChatCommand(){this.plugin.addCommand({id:De,name:"Clear chat (except frontmatter)",icon:"trash",editorCallback:async(e,t)=>{this.serviceLocator.getEditorService().clearChat(e)}})}getAiApiUrls(e){return{openai:e.openaiUrl||A.url,openrouter:e.openrouterUrl||C.url,ollama:e.ollamaUrl||M.url,lmstudio:e.lmstudioUrl||E.url}}async initializeAvailableModels(){console.log("[ChatGPT MD] Initializing available models...");try{let e=this.settingsService.getSettings(),t=this.apiAuthService.getApiKey(e,h),r=this.apiAuthService.getApiKey(e,d),i={[h]:e.openaiUrl||A.url,[d]:e.openrouterUrl||C.url,[g]:e.ollamaUrl||M.url,[S]:e.lmstudioUrl||E.url};this.availableModels=await this.fetchAvailableModels(i,t,r),console.log(`[ChatGPT MD] Found ${this.availableModels.length} available models.`)}catch(e){console.error("[ChatGPT MD] Error initializing available models:",e),this.availableModels=[]}}async fetchAvailableModels(e,t,r){function i(n,o,s){return Promise.race([n,new Promise(a=>setTimeout(()=>a(s),o))])}try{let n=new v,o=[];return o.push(i(Qe(e[g]),Y,[])),o.push(i(tt(e[S]),Y,[])),P(t)&&o.push(i(Ze(e[h],t),Y,[])),P(r)&&o.push(i(et(e[d],r),Y,[])),(await Promise.all(o)).flat()}catch(n){return new $.Notice("Error fetching models: "+(n instanceof Error?n.message:String(n))),console.error("Error fetching models:",n),[]}}updateStatusBar(e){this.statusBarItemEl.setText(`[ChatGPT MD] ${e}`)}};var fe=class extends rt.Plugin{async onload(){this.serviceLocator=new he(this.app,this);let e=this.serviceLocator.getSettingsService();await e.loadSettings(),await e.migrateSettings(),await e.addSettingTab(),this.commandRegistry=new ue(this,this.serviceLocator,e),this.commandRegistry.registerCommands(),this.commandRegistry.initializeAvailableModels().catch(t=>{console.error("[ChatGPT MD] Error initializing models in background:",t)})}};

/* nosourcemap */